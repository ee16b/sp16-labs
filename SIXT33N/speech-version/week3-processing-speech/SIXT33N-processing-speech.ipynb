{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIXT33N Project\n",
    "## Phase 2: Processing Integration - Speech\n",
    "\n",
    "### EE 16B: Designing Information Devices and Systems II, Spring 2016\n",
    "\n",
    "Written by Nathaniel Mailoa and Emily Naviasky (2016)\n",
    "\n",
    "nmailoa@berkeley.edu &emsp; enaviasky@berkeley.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name 1**:\n",
    "\n",
    "**Login**: ee16b-\n",
    "\n",
    "\n",
    "**Name 2**:\n",
    "\n",
    "**Login**: ee16b-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Introduction](#intro)\n",
    "* [Part 1: Real Data Collection](#part1)\n",
    "* [Part 2: Real Data Classification](#part2)\n",
    "* [Part 3: Launchpad Implementation](#part3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "In this phase you will merge the microphone front-end circuit and the PCA classification that you built in the last phase. You will re-record sample data, now using your own microphone circuit. You will then re-run the PCA classification and, when you think it is good enough, implement it in the Launchpad. The Launchpad will print out the word it identifies when you speak a command. Since this phase requires both the circuit and the PCA components, one of the students working on this phase should be from the team that worked on the circuit and the other student from the team that worked on the PCA classification.\n",
    "\n",
    "As mentioned in the main project page, there is a checkpoint every week. Each checkpoint is worth 5 points, and if you are late you are awarded 4 points. The checkpoints are due in the beginning of the lab in the week after. For this phase, the checkpoints (marked **<span style=\"color:green\">green</span>** in the Notebook) are:\n",
    "- Week 1: Take new data and run through PCA, show GSI results in Python\n",
    "- Week 2: Classification reasonably accurate in Launchpad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part1'></a>\n",
    "## <span style=\"color:blue\">Part 1: Real Data Collection</span>\n",
    "\n",
    "### Materials\n",
    "- Microphone front-end circuit\n",
    "- Launchpad + USB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, you got a feel for which words are easy to distinguish between. Now that you have chosen your command words, you will have to collect your real training data. You cannot use your old data because the noise and filtering of the micboard will be different from the front end you just built. You will have to collect a new final set of data, and you will want to collect more data for this stage than you did before.\n",
    "\n",
    "First, you will need to replace the micboard with your newly breadboarded mic circuit. Just as in the PCA phase, disconnect the 5V jumper on the Launchpad, because you will power the Launchpad from the power supply. <b>Make sure to keep the jumper on just the pin closest to the USB and put it back at the end of the lab.</b> Do not power up your circuit for now, we will connect the appropriate Launchpad pins to your circuit first:\n",
    "- P6.0 to the microphone front end circuit output\n",
    "- 3.3V pin to the 3V power rail of the breadboard (in particular to supply the buffer op-amp)\n",
    "- 5V pin to the 5V power rail of the breadboard\n",
    "- GND pin to the ground rail of the breadboard\n",
    "\n",
    "Next, use the bench power supply to provide 5V to the circuit. **<span color='red'>DO NOT FORGET TO SET THE CURRENT LIMIT.</span>** Before you start recording, use the oscilloscope to probe the output of the microphone circuit. Make sure the waveform averages to 1.65V (halfway between 0V and 3.3V) and the amplitude is large enough.\n",
    "\n",
    "Just as before, to collect speech data, upload the provided sketch <b>`collect-data-envelope.ino`</b> from the PCA phase to your Launchpad. As a reminder, this sketch will turn on the red Launchpad LED to show that it is recording. The Launchpad will record 2 seconds of audio at a time, sampled every 0.35ms. When the red LED lights up, say the word you want to record before it turns off.\n",
    "\n",
    "To record the data in the PC, run:\n",
    "\n",
    "<b>`python collect-data-envelope.py log.csv`</b>\n",
    "\n",
    "This will append the data streamed back by the Launchpad to `log.csv`. Collect data for the 4 words that you have successfully classified in the PCA phase. You might want to look at your circuit output on the scope while you record. Make sure that your commands are not too loud and getting clipped, nor too soft and hard to pick out from noise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part2'></a>\n",
    "## <span style=\"color:blue\">Part 2: Real Data Classification</span>\n",
    "\n",
    "### Materials\n",
    "- PC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have some data, go back to the iPython Notebook from the PCA phase and re-run the code. You should not need to modify anything - just run the whole notebook and evaluate the final clustering results. Are the words clustering well? Is your classification accuracy still high enough? If your accuracy was previously very high but it is now much lower, you may have over fit your data. You may need to tweak some of your parameters in order to get good enough accuracy again. Go back and think of other ways to make the classification more robust or choose other words that might be able to be classified better. If you're stuck, ask your GSI for help.\n",
    "\n",
    "If you're happy with the clustering, print out the PCA vector and mean vector (the mean of the columns). You will need them soon. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width='30px' align='left' src=\"http://inst.eecs.berkeley.edu/~ee16b/sp16/lab_pics/check.png\">\n",
    "<br/>\n",
    "## <span style=\"color:green\">CHECKPOINT 1</span>\n",
    " <span style=\"color:green\">**Show your GSI the clustering of the data using real data.** Is your classification accuracy still high enough?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part3'></a>\n",
    "## <span style=\"color:blue\">Part 3: Launchpad Implementation</span>\n",
    "\n",
    "### Materials\n",
    "- Microphone front-end circuit\n",
    "- Launchpad + USB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your last step will be to implement your <b>data processing</b> and <b>classification</b> (just the projection, not the PCA) in the Launchpad sketch <b>`classify.ino`</b>. Energia uses the Arduino language, which is very close to C. If you need a refresher or a quick start, there are many C tutorials in the web. Quickly glance through <b>`classify.ino`</b>. It contains the same base code as the <b>`collect-data-envelope.ino`</b> from before, with some extra functionality. Since Energia does not have as many in-built functions as Python, you might have to write out the functions yourself. For example, a dot product should be written as:\n",
    "\n",
    "`float result = 0;`<br/>\n",
    "`for (i=0; i<LENGTH; i++){`<br/>\n",
    "&emsp; `result += vector1[i]*vector2[i];`<br/>\n",
    "`}`\n",
    "\n",
    "For debugging purposes, printing looks like the line below. The Launchpad will print the string out in Energia's Serial Monitor through the USB cable.\n",
    "\n",
    "<code>Serial.println(\"I'm being printed!\");</code>\n",
    "\n",
    "Open up <b>`classify.ino`</b> and get a feel for what some of the code is doing. Note that there are 2 code blocks (A1 and B) that you need to modify. <b>You should not have to change anything else outside these marked code blocks.</b> \n",
    "\n",
    "First, fill in some constant parameters in **`CODE BLOCK A1`**. The `SNIPPET_SIZE`, `PRELENGTH` and `THRESHOLD` constants are found from the arguments to the enveloping function in the PCA classification phase. \n",
    "\n",
    "The `KMEANS_THRESHOLD` is the variable we suggest you use to decide whether to accept or regect a classification depending on a sample's distance from the closest centroid. If the L2 norm (distance) is larger than the threshold, your classification algorithm should simply ignore it and wait for the next sample. Look at the plot of sample data and the centroids from the PCA Notebook and approximate a radius around the centroids that capture most of the data. Try to be conservative - it's better to not classify than to misclassify.\n",
    "\n",
    "The `LOUDNESS_THRESHOLD` variable decides whether to accept a classification depending on the amplitude of the recorded data. If the recorded data is too soft, we do not want to classify it as it is probably noise. Since the loudness unit is arbitrary, start by using `700`. Later, if the Launchpad classifies noise, increase this constant. If it misses a lot of speech (i.e. thinks your word is noise), decrease this constant.\n",
    "\n",
    "Secondly, fill in the arrays in **`CODE BLOCK A2`**. These are the PCA bases and mean vector, as well as the K-means classification centroids. If you need more than 2 principal components, add a new `pca_vec3` array. Remember, if you are using more than two principal components, then the dimensionality of all of your point and the centriods has increased. The centroid arrays should be the same length as the number of principal components you use. An example of filling up an array of 3 rather than two elements is shown below for syntax.\n",
    "\n",
    "<code>float centriod1[3] = {0.1234, 0.5678, 0.9012};</code>\n",
    "\n",
    "Now go to **`CODE BLOCK B`**. This is the meat of the classification. Before this block, the call to `envelope` leaves the data vector in the array called `result`. You will write the code to project this data array onto your new PCA basis. Remember that you will still need to subtract the mean vector, before doing a dot product for each basis. We recommend using the variables `proj1` and `proj2` to store the projection results.\n",
    "\n",
    "Next, code the K-means classification using the centroid arrays. Find the distance between the projected data point and each centroid using the function `l2_norm` (for 2 principal components) or `l2_norm3` (for 3 principal components). These functions take the data point coordinates and the centroid array. Look up the function definition in the sketch. Out of the 4 centroids, find the one with the smallest L2 norm from the data point. This is the word you classified.\n",
    "\n",
    "Before saying you have classified a word, however, you will want to check the distance first. If the distance is greater than `KMEANS_THRESHOLD`, the data point is not close enough for you to guess with some certainty. Thus, we only consider a data point to be classified if the distance is less than this constant.\n",
    "\n",
    "When you have classified a data point, print out the word on Serial. You should be able to see the printout from Energia's Serial Monitor.\n",
    "\n",
    "Before running the code in the Launchpad, use the oscilloscope to probe the circuit output again and make sure that it still averages around 1.65V. Now upload the sketch to your Launchpad and run it. Open the Serial Monitor and press the reset button. Say your word and the Launchpad should recognize your word as it gets printed on the Serial Monitor!\n",
    "\n",
    "If the Launchpad does not classify as well as you think it should, remember to play with the `KMEANS_THRESHOLD` and `LOUDNESS_THRESHOLD` variables. To debug the sketch, you can also print out any of the variables you have used. \n",
    "\n",
    "Voila! Your SIXT33N can recognize your words! If you still have time, help the controls pair finish their phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width='30px' align='left' src=\"http://inst.eecs.berkeley.edu/~ee16b/sp16/lab_pics/check.png\">\n",
    "<br/>\n",
    "## <span style=\"color:green\">CHECKPOINT 2</span>\n",
    " <span style=\"color:green\">**Show your GSI the Launchpad recognizing words.** Make sure the correct identified word is printed in the Serial Monitor.</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
